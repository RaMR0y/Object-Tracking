{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzD3AEbjGQ1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ef2631-e373-4d50-ba9b-fb75fe90f3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl-rv57JG6ou"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = '/content/gdrive/My Drive/Yolov8'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxzMvSJBh9co"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install deep-sort-realtime\n",
        "!pip install filterpy\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Object Tracking with Adaptive Tracker Switching\n",
        "\n",
        "This notebook implements an object tracking system that utilizes YOLOv8 with custom and sorted dataset for object detection and employs adaptive switching between different tracking algorithms (Simple, DeepSORT, Particle Filter) to enhance tracking performance.\n",
        "\n",
        "## Functionality:\n",
        "\n",
        "1. **Object Detection:**\n",
        "   - The system uses a pre-trained YOLOv8 model (`yolov8n.pt`) to detect objects in video frames.\n",
        "   - Detections are represented by bounding boxes and confidence scores.\n",
        "\n",
        "2. **Tracking Algorithms:**\n",
        "   - **Simple Tracker:** A basic tracker that assigns unique IDs to detected objects and updates their positions in subsequent frames.\n",
        "   - **DeepSORT Tracker:** A more sophisticated tracker that utilizes deep learning features and a Kalman filter for robust tracking and re-identification of objects.\n",
        "   - **Particle Filter Tracker:** Intended to provide an alternative tracking approach for potentially challenging scenarios using a Kalman filter.\n",
        "\n",
        "3. **Adaptive Switching:**\n",
        "   - The system continuously monitors the quality of tracking using a heuristic function (`tracking_quality_low`).\n",
        "   - If the tracking quality falls below a certain threshold, the system automatically switches to a more robust tracker (from Simple to DeepSORT to Particle Filter).\n",
        "   - Hysteresis is implemented to prevent rapid and unstable switching.\n",
        "\n",
        "4. **Visualization:**\n",
        "   - Tracked objects are visualized by drawing bounding boxes and displaying their IDs on the video frames.\n",
        "\n",
        "## Code Structure:\n",
        "\n",
        "- **`SimpleTracker` Class:** Implements the basic tracking logic.\n",
        "- **`DeepSORTTracker` Class:** Integrates DeepSORT for robust tracking.\n",
        "- **`ParticleFilterTracker` Class:** Provides an alternative tracking approach using a Kalman filter.\n",
        "- **`tracking_quality_low` Function:** Evaluates the quality of tracking based on various metrics.\n",
        "- **`track_video` Function:** Orchestrates the entire tracking process, including object detection, tracker updates, and visualization.\n",
        "\n",
        "## Usage:\n",
        "\n",
        "1. There is already a video, in order to use it, it needs access to local google drive with the location of the video.\n",
        "2. Execute the notebook cells to run the object tracking system.\n",
        "\n",
        "## Limitations:\n",
        "\n",
        "- The particle filter implementation might need further refinement.\n",
        "- The tracking quality metric could be fine-tuned for better performance.\n",
        "- More comprehensive visualization and quantitative evaluation would be beneficial.\n",
        "\n",
        "## Future Enhancements:\n",
        "\n",
        "- Implement a true particle filter to account for non-linear systems and non-gaussian noise.\n",
        "- Explore more advanced tracking quality metrics and switching strategies.\n",
        "- Add visualizations and quantitative evaluation using metrics like MOTA, MOTP, and IDF1.\n",
        "- Enhance documentation and add comments for better readability.\n"
      ],
      "metadata": {
        "id": "c59vfhXRC3Lt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySTNfkrqh2QY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from filterpy.kalman import KalmanFilter\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data='coco8.yaml', epochs=50, imgsz=640)\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.val()\n",
        "\n",
        "# Feature Extraction Hook\n",
        "features = []\n",
        "\n",
        "def hook_fn(module, input, output):\n",
        "    features.append(output)\n",
        "\n",
        "# Register hook for feature extraction\n",
        "layer_to_hook = model.model.model[2]\n",
        "hook = layer_to_hook.register_forward_hook(hook_fn)\n",
        "\n",
        "# Helper function to format YOLO detections\n",
        "def format_detections(results):\n",
        "    formatted_detections = []\n",
        "    for det in results:\n",
        "        x1, y1, x2, y2, conf = det[:5]\n",
        "        formatted_detections.append([x1, y1, x2, y2, conf])\n",
        "    return np.array(formatted_detections)\n",
        "\n",
        "# SimpleTracker implementation\n",
        "class SimpleTracker:\n",
        "    def __init__(self):\n",
        "        self.tracks = {}\n",
        "        self.next_id = 0\n",
        "\n",
        "    def update(self, detections):\n",
        "        updated_tracks = []\n",
        "        for det in detections:\n",
        "            bbox = det[:4]\n",
        "            track_id = self.next_id\n",
        "            self.tracks[track_id] = bbox\n",
        "            self.next_id += 1\n",
        "            updated_tracks.append({\"id\": track_id, \"bbox\": bbox})\n",
        "        return updated_tracks\n",
        "\n",
        "# DeepSORT Tracker\n",
        "class DeepSORTTracker:\n",
        "    def __init__(self):\n",
        "        self.tracker = DeepSort(max_age=30, n_init=3)\n",
        "\n",
        "    def update(self, detections, features):\n",
        "        return self.tracker.update_tracks(detections, features)\n",
        "\n",
        "# Particle Filter Tracker\n",
        "class ParticleFilterTracker:\n",
        "    def __init__(self):\n",
        "        self.filters = {}\n",
        "        self.next_id = 0\n",
        "\n",
        "    def create_particle_filter(self):\n",
        "        pf = KalmanFilter(dim_x=8, dim_z=4)  # [x, y, w, h, vx, vy, vw, vh]\n",
        "        pf.x = np.zeros(8)  # Initial state\n",
        "        pf.P *= 10  # Covariance matrix\n",
        "        pf.R *= 10  # Measurement noise\n",
        "        return pf\n",
        "\n",
        "    def update(self, detections):\n",
        "        updated_tracks = []\n",
        "        for det in detections:\n",
        "            track_id = self.next_id\n",
        "            if track_id not in self.filters:\n",
        "                self.filters[track_id] = self.create_particle_filter()\n",
        "            pf = self.filters[track_id]\n",
        "            pf.predict()\n",
        "            pf.update(np.array(det[:4]))  # Measurement update\n",
        "            self.next_id += 1\n",
        "            updated_tracks.append({\"id\": track_id, \"bbox\": det[:4]})\n",
        "        return updated_tracks\n",
        "\n",
        "# Helper function to calculate tracking quality metrics\n",
        "def calculate_quality_score(tracked_objects, previous_objects):\n",
        "    # Example metrics: average tracking duration, bounding box overlap, etc.\n",
        "    avg_duration = np.mean([obj['id'] for obj in tracked_objects]) if tracked_objects else 0\n",
        "    overlap = 0  # Placeholder for overlap calculation logic\n",
        "    return avg_duration + overlap\n",
        "\n",
        "# Helper function to determine tracking quality with hysteresis\n",
        "def tracking_quality_low(tracked_objects, previous_objects, tracker_type_history):\n",
        "    quality_score = calculate_quality_score(tracked_objects, previous_objects)\n",
        "    quality_threshold = 5  # Adjust as needed\n",
        "    return quality_score < quality_threshold\n",
        "\n",
        "# Main function for video processing and tracking\n",
        "def track_video(video_path):\n",
        "    if not os.path.exists(video_path):\n",
        "        raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    simple_tracker = SimpleTracker()\n",
        "    deepsort_tracker = DeepSORTTracker()\n",
        "    particle_filter_tracker = ParticleFilterTracker()\n",
        "\n",
        "    # Start with the SimpleTracker\n",
        "    current_tracker = simple_tracker\n",
        "    tracker_type = \"simple\"\n",
        "\n",
        "    previous_objects = []\n",
        "    tracker_type_history = []\n",
        "    low_quality_frames = 0\n",
        "    quality_threshold_frames = 5\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # YOLOv8 detection\n",
        "        results = model(frame)[0]\n",
        "        detections = results.boxes.data.cpu().numpy()\n",
        "\n",
        "        # Clear and extract features\n",
        "        features.clear()\n",
        "        _ = model(frame)\n",
        "\n",
        "        # Update tracker based on type\n",
        "        if tracker_type == \"simple\":\n",
        "            tracked_objects = current_tracker.update(detections)\n",
        "            if tracking_quality_low(tracked_objects, previous_objects, tracker_type_history):\n",
        "                low_quality_frames += 1\n",
        "                if low_quality_frames >= quality_threshold_frames:\n",
        "                    current_tracker = deepsort_tracker\n",
        "                    tracker_type = \"deepsort\"\n",
        "                    low_quality_frames = 0\n",
        "        elif tracker_type == \"deepsort\":\n",
        "            formatted_detections = format_detections(detections)\n",
        "            tracked_objects = current_tracker.update(formatted_detections, features)\n",
        "            if tracking_quality_low(tracked_objects, previous_objects, tracker_type_history):\n",
        "                low_quality_frames += 1\n",
        "                if low_quality_frames >= quality_threshold_frames:\n",
        "                    current_tracker = particle_filter_tracker\n",
        "                    tracker_type = \"particle\"\n",
        "                    low_quality_frames = 0\n",
        "        else:  # Particle Filter\n",
        "            tracked_objects = current_tracker.update(detections)\n",
        "\n",
        "        # Update previous objects\n",
        "        previous_objects = tracked_objects\n",
        "\n",
        "        # Visualize results\n",
        "        for obj in tracked_objects:\n",
        "            x1, y1, x2, y2 = map(int, obj['bbox'])\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"ID: {obj['id']}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "        cv2_imshow(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Example usage\n",
        "video_path = '/content/gdrive/My Drive/Yolov8/test.mp4'\n",
        "track_video(video_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}